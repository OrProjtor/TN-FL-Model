{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from source.general_functions import (\n",
    "    prepare_for_dump,\n",
    "    extend_results_dict,\n",
    "    create_dir_if_not_exists,\n",
    ")\n",
    "from source.experiment_functions import ( \n",
    "    data2train_f,\n",
    "    get_res_table,\n",
    "    plot_mean_conf,\n",
    "    data2model_params,\n",
    "    prepare_train_funct_fl,\n",
    "    get_stats_several_trials,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### DO NOT CHANGE ###\n",
    "N_TRIALS = 10\n",
    "TEST_SIZE = 0.2\n",
    "METRIC_F = mean_squared_error\n",
    "P_SCALE_LIST = [10, 2, 128, 25, 64, 600, 2000, 1024]\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "### DO NOT CHANGE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Airline Data:\n",
    "\n",
    "You have to download the Airline dataset. Check out the following resources:\n",
    "- J. Hensman, N. Fusi, and N. D. Lawrence. Gaussian processes for Big data. In Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence, UAI’13, pages 282–290, Arlington, Virginia, USA, Aug. 2013. AUAI Press.\n",
    "- J. Hensman, N. Durrande, and A. Solin. Variational Fourier features for Gaussian processes. The Journal of Machine Learning Research, 18(1):5537–5588, Jan. 2017. ISSN 1532-4435.\n",
    "\n",
    "Once you obtain the dataset, run the next cell filling in the path to the Airline file (raw dataset). This is a preprocessing step.\n",
    "\n",
    "Note: If you don't do this step you will not get the results for Airline dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_airline\n",
    "\n",
    "path_raw_airline = '' # Fill in the path to the raw Airline data \n",
    "load_airline(path_raw_airline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Optimization Problems (Regularization for $\\lambda$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT CHANGE ###\n",
    "DATA_NAMES = ['energy', 'yacht', 'concrete', 'airfoil', 'wine']\n",
    "RES_PATH = (\n",
    "    create_dir_if_not_exists(f'./artifacts/Regularization_Study') \n",
    "    / 'results.json'\n",
    ")\n",
    "### DO NOT CHANGE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instructions: ###\n",
    "# If the results have already been obtained, \n",
    "# you can set TRAIN = False to prevent extra calculations.\n",
    "TRAIN = True \n",
    "\n",
    "if TRAIN:  \n",
    "    final_res = defaultdict(dict)\n",
    "    for data_name in DATA_NAMES:  \n",
    "        print(data_name)\n",
    "        DATA_PATH = DATA_DIR / f'{data_name}.csv'\n",
    "        for reg_type in ['l1', 'l2', 'fixed_norm']:\n",
    "            for l_pos in [True, False]:\n",
    "                train_model_f = prepare_train_funct_fl(\n",
    "                    data2model_params(data_name, 'FL_Model', P_SCALE_LIST, reg_type, l_pos)\n",
    "                )\n",
    "                res = get_stats_several_trials(\n",
    "                    DATA_PATH, train_model_f, METRIC_F, N_TRIALS, TEST_SIZE\n",
    "                )\n",
    "                mode = reg_type + ('_pos' if l_pos else '')\n",
    "                final_res[data_name][mode] = res\n",
    "    with open(RES_PATH, 'w') as outfile:\n",
    "        json.dump(final_res, outfile)\n",
    "else:\n",
    "    with open(RES_PATH, 'r') as f:\n",
    "        final_res = json.load(f)\n",
    "\n",
    "dict_final_res = defaultdict(list)\n",
    "for data_name in DATA_NAMES:  \n",
    "    for reg_type in ['l1', 'l2', 'fixed_norm']:\n",
    "        for l_pos in [True, False]:\n",
    "            mode = reg_type + ('_pos' if l_pos else '')\n",
    "            dict_final_res['data'].append(data_name)\n",
    "            dict_final_res['Regularization'].append(mode)\n",
    "            dict_final_res['MSE'].append(np.mean(final_res[data_name][mode]['metric']))\n",
    "            dict_final_res['Time'].append(np.mean(final_res[data_name][mode]['train_time']))\n",
    "display(\n",
    "    pd.pivot(\n",
    "        pd.DataFrame(dict_final_res), \n",
    "        columns=['data'], \n",
    "        index=['Regularization']\n",
    "    ).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FL Model Compared to Cross-Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamical Behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT CHANGE ###\n",
    "DATA_NAMES = ['energy', 'yacht', 'concrete', 'airfoil', 'wine'] \n",
    "\n",
    "if 'airline' in ';'.join(os.listdir('./data')):\n",
    "    DATA_NAMES.append('airline')\n",
    "else:\n",
    "    print('There will be no Airline data results!')\n",
    "### DO NOT CHANGE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instructions: ###\n",
    "# Set TRAIN = False only if you already have the results for all the datasets\n",
    "TRAIN = True\n",
    "\n",
    "if TRAIN:\n",
    "    for data_name in DATA_NAMES:  \n",
    "        print(data_name)\n",
    "        DATA_PATH = DATA_DIR / f'{data_name}.csv'\n",
    "        RES_PATH = create_dir_if_not_exists(f'./artifacts/FLvsCV/{data_name}') / 'results.json'\n",
    "        res = defaultdict(list)\n",
    "        for model_name in ['FL_Model', 'CV_Model']:\n",
    "            if data_name == 'airline':\n",
    "                test_size, n_trials, p_scale_list = 0.3, 5, [10, 2, 128, 25, 64, 1024]\n",
    "                train_model_f = data2train_f(data_name, model_name, p_scale_list)\n",
    "                _res = get_stats_several_trials(\n",
    "                    DATA_PATH, train_model_f, METRIC_F, n_trials, test_size\n",
    "                )\n",
    "                extend_results_dict(res, n_features=[len(p_scale_list),]*n_trials, **_res)\n",
    "            else:\n",
    "                for nps in range(1, len(P_SCALE_LIST) + 1):\n",
    "                    p_scale_list = P_SCALE_LIST[:nps]\n",
    "                    train_model_f = data2train_f(data_name, model_name, p_scale_list)\n",
    "                    _res = get_stats_several_trials(\n",
    "                        DATA_PATH, train_model_f, METRIC_F, N_TRIALS, TEST_SIZE\n",
    "                    )\n",
    "                    extend_results_dict(res, n_features=[nps,]*N_TRIALS, **_res)\n",
    "        res = prepare_for_dump(res)\n",
    "        with open(RES_PATH, 'w') as outfile:\n",
    "            json.dump(res, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamical Behavior of Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instructions: ###\n",
    "# Choose the dataset: \n",
    "# DATA_NAME = 'yacht' / 'airfoil' / 'energy' / 'concrete' / 'wine'\n",
    "DATA_NAME = 'yacht' \n",
    "\n",
    "RES_DIR = create_dir_if_not_exists(f'./artifacts/FLvsCV')\n",
    "RES_PATH = RES_DIR / f'{DATA_NAME}/results.json'\n",
    "with open(RES_PATH, 'r') as f:\n",
    "    df_res = pd.DataFrame(json.load(f))\n",
    "\n",
    "show_plot = True\n",
    "y_scale_mse = 'linear'\n",
    "_title = f'({DATA_NAME.capitalize()} dataset)'\n",
    "params_list = [\n",
    "    dict(\n",
    "        y_col='train_time', \n",
    "        y_label='Train Time (sec.)', \n",
    "        title=f'Training Time vs #Features {_title}',\n",
    "        y_scale='linear',\n",
    "    ),\n",
    "    dict(\n",
    "        y_col='metric', \n",
    "        y_label=f'{y_scale_mse}(MSE)' if y_scale_mse == 'log' else 'MSE', \n",
    "        title=f'Prediction quality vs #Features {_title}', \n",
    "        y_scale=y_scale_mse,\n",
    "    ),\n",
    "]\n",
    "\n",
    "for i, params in enumerate(params_list):\n",
    "    x_col, y_col, y_label = 'n_features', params['y_col'], params['y_label']\n",
    "    title, y_scale = params['title'], params['y_scale']\n",
    "    grouped_df = (\n",
    "        df_res.groupby([x_col, 'model'])[y_col].agg(['mean', 'std'])\n",
    "        .reset_index().rename(columns={'mean': y_col}))\n",
    "    \n",
    "    grouped_df['model'] = grouped_df['model'].str.removesuffix('_Model')\n",
    "    save_path = RES_DIR / f'{DATA_NAME}/{y_col}.png'\n",
    "    \n",
    "    plot_mean_conf(\n",
    "        grouped_df, x_col, y_col, 'std', 'model', '#Features (P)', y_label, \n",
    "        '', save_path, show_plot, y_scale, grouped_df[x_col].unique(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table: Comparison of FL Model and CV for Small/Large-Scale Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(get_res_table(DATA_NAMES, len(P_SCALE_LIST), DATA_DIR)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
